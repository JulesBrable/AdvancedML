{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from src.etl.utils import download_data_from_uciml, load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>$('.output_scroll').removeClass('output_scroll')</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "js = \"<script>$('.output_scroll').removeClass('output_scroll')</script>\"\n",
    "display(HTML(js))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data_from_uciml(id=544)\n",
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2111, 16) (2111,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                             object\n",
       "Age                               float64\n",
       "Height                            float64\n",
       "Weight                            float64\n",
       "family_history_with_overweight     object\n",
       "FAVC                               object\n",
       "FCVC                              float64\n",
       "NCP                               float64\n",
       "CAEC                               object\n",
       "SMOKE                              object\n",
       "CH2O                              float64\n",
       "SCC                                object\n",
       "FAF                               float64\n",
       "TUE                               float64\n",
       "CALC                               object\n",
       "MTRANS                             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = y.value_counts()\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plot_df.plot(kind='bar', color='skyblue')\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Count of Each Category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data for y: \n",
      " 0\n",
      "Missing data for X: \n",
      " Gender                            0\n",
      "Age                               0\n",
      "Height                            0\n",
      "Weight                            0\n",
      "family_history_with_overweight    0\n",
      "FAVC                              0\n",
      "FCVC                              0\n",
      "NCP                               0\n",
      "CAEC                              0\n",
      "SMOKE                             0\n",
      "CH2O                              0\n",
      "SCC                               0\n",
      "FAF                               0\n",
      "TUE                               0\n",
      "CALC                              0\n",
      "MTRANS                            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "[print(f\"Missing data for {data}: \\n {globals()[data].isna().sum()}\") for data in [\"y\", \"X\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, y):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset: Encode categorical variables, normalize numerical variables, and convert to PyTorch tensors.\n",
    "\n",
    "    Parameters:\n",
    "    X (DataFrame): The feature dataset.\n",
    "    y (Series): The target variable.\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    X (Tensor): The preprocessed features as a tensor\n",
    "    y (Tensor): The preprocessed target variable as a tensor\n",
    "    \"\"\"\n",
    "    categorical_features = X.select_dtypes(include=['object']).columns\n",
    "    numeric_features = X.select_dtypes(include=['float64']).columns\n",
    "    \n",
    "    y = pd.get_dummies(y).values\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(), categorical_features)])\n",
    "\n",
    "    X = preprocessor.fit_transform(X)\n",
    "    X, y = [torch.tensor(z, dtype=torch.float32) for z in [X, y]]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_model(model, criterion, optimizer, train_loader, val_loader, epochs: int):\n",
    "    \"\"\"\n",
    "    Train and validate the PyTorch model, returning the history of training and validation losses.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model to be trained and validated\n",
    "    criterion (Callable): Loss function\n",
    "    optimizer (torch.optim.Optimizer): Optimizer\n",
    "    train_loader (DataLoader): DataLoader for the training set\n",
    "    val_loader (DataLoader): DataLoader for the validation set\n",
    "    epochs (int): Number of training epochs\n",
    "\n",
    "    Returns:\n",
    "    Tuple[List[float], List[float]]: Lists of average training and validation losses per epoch\n",
    "    \"\"\"\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "                total_val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluate the PyTorch model.\n",
    "\n",
    "    Parameters:\n",
    "    model: The PyTorch model to be evaluated\n",
    "    test_loader: DataLoader for the test set\n",
    "\n",
    "    Returns:\n",
    "    accuracy (float): The accuracy of the model on the test set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List\n",
    "\n",
    "def perform_cross_validation(model_factory: Callable[[int, int], torch.nn.Module], \n",
    "                             optimizer_factory: Callable[[torch.nn.Module], torch.optim.Optimizer],\n",
    "                             X: torch.Tensor, \n",
    "                             y: torch.Tensor, \n",
    "                             k_folds: int,\n",
    "                             epochs: int = 70) -> List[float]:\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation and return average test accuracy, training losses, and validation losses.\n",
    "\n",
    "    Parameters:\n",
    "    model_factory (Callable[[int, int], torch.nn.Module]): Factory function to create a new instance of the model\n",
    "    optimizer_factory (Callable[[torch.nn.Module], torch.optim.Optimizer]): Factory function to create a new optimizer\n",
    "    X (torch.Tensor): The features\n",
    "    y (torch.Tensor): The target variable\n",
    "    k_folds (int): Number of folds in cross-validation\n",
    "\n",
    "    Returns:\n",
    "    Tuple[float, List[List[float]], List[List[float]]]: Average accuracy, training losses, validation losses\n",
    "    \"\"\"\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "    all_train_losses, all_val_losses = [], []\n",
    "\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(X)):\n",
    "        # Split data for the fold\n",
    "        X_train, X_test = X[train_ids], X[test_ids]\n",
    "        y_train, y_test = y[train_ids], y[test_ids]\n",
    "\n",
    "        # DataLoaders\n",
    "        train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=32)\n",
    "        test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=32)\n",
    "        \n",
    "        # Determine input and output sizes\n",
    "        input_size = X_train.shape[1]\n",
    "        output_size = y_train.shape[1] # assuming y_train is one-hot encoded\n",
    "\n",
    "        # Initialize model for the current fold\n",
    "        model = model_factory(input_size, output_size)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optimizer_factory(model)\n",
    "            \n",
    "        train_losses, val_losses = train_validate_model(model, criterion, optimizer, train_loader, val_loader, epochs)\n",
    "        all_train_losses.append(train_losses)\n",
    "        all_val_losses.append(val_losses)\n",
    "\n",
    "        fold_accuracy = evaluate_model(model, test_loader)\n",
    "        print(f'Fold {fold+1}, Accuracy: {fold_accuracy}%')\n",
    "        fold_accuracies.append(fold_accuracy)\n",
    "        \n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    return avg_accuracy, all_train_losses, all_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_losses(train_losses, val_losses, opti: str, model: str, save: bool = False):\n",
    "    \"\"\"\n",
    "    Plot the training and validation loss curves.\n",
    "\n",
    "    Parameters:\n",
    "    train_losses (List[List[float]]): Training losses for each fold\n",
    "    val_losses (List[List[float]]): Validation losses for each fold\n",
    "    \"\"\"\n",
    "    avg_train_losses = np.mean(train_losses, axis=0)\n",
    "    avg_val_losses = np.mean(val_losses, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(avg_train_losses, label='Average Training Loss')\n",
    "    plt.plot(avg_val_losses, label='Average Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training and Validation Loss Curves for {model} with {opti} optimizer')\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'../assets/img/curves_{model}_{opti.lower()}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_grid = {\n",
    "    'lr': [0.001, 0.0005, 0.0001, 0.00005],\n",
    "    'betas': [(0.9, 0.999), (0.95, 0.999), (0.85, 0.995)]\n",
    "}\n",
    "\n",
    "sgd_grid = {\n",
    "    'lr': [0.01, 0.005, 0.001, 0.0005],\n",
    "    'momentum': [0.95, 0.9, 0.8],\n",
    "    'nesterov': [True]\n",
    "}\n",
    "\n",
    "adagrad_grid = {\n",
    "    'lr': [0.01, 0.005, 0.001, 0.0005]\n",
    "}\n",
    "\n",
    "rmsprop_grid = {\n",
    "    'lr': [0.01, 0.001, 0.0001],\n",
    "    'alpha': [0.99, 0.9],\n",
    "    'momentum': [0.95, 0.9, 0.8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def grid_search_optimizer(model_factory, optimizer_factory, param_grid, X, y, k_folds=5, epochs=70):\n",
    "    best_accuracy = 0\n",
    "    best_params = None\n",
    "\n",
    "    for params in product(*param_grid.values()):\n",
    "        # Set the parameters for the optimizer\n",
    "        optimizer_params = dict(zip(param_grid.keys(), params))\n",
    "        optimizer = lambda model: optimizer_factory(model, **optimizer_params)\n",
    "\n",
    "        # Perform cross-validation\n",
    "        avg_accuracy, _, _ = perform_cross_validation(model_factory, optimizer, X, y, k_folds, epochs)\n",
    "\n",
    "        if avg_accuracy > best_accuracy:\n",
    "            best_accuracy = avg_accuracy\n",
    "            best_params = optimizer_params\n",
    "\n",
    "        print(f\"Params: {optimizer_params}, Accuracy: {avg_accuracy:.2f}%\")\n",
    "\n",
    "    return best_params, best_accuracy\n",
    "\n",
    "def adam_factory(model, lr, betas):\n",
    "    return optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "def sgd_nesterov_factory(model, lr, momentum, nesterov=True):\n",
    "    return optim.SGD(model.parameters(), lr=lr, momentum=momentum, nesterov=nesterov)\n",
    "\n",
    "def adagrad_factory(model, lr):\n",
    "    return optim.Adagrad(model.parameters(), lr=lr)\n",
    "\n",
    "def rmsprop_factory(model, lr, alpha):\n",
    "    return torch.optim.RMSprop(model.parameters(), lr=lr, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class ComplexNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(ComplexNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.relu3(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "logistic_regression_factory = lambda input_size, output_size: LogisticRegression(input_size, output_size)\n",
    "simple_nn_factory = lambda input_size, output_size: SimpleNN(input_size, output_size)\n",
    "complex_nn_factory = lambda input_size, output_size: ComplexNN(input_size, output_size)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': logistic_regression_factory,\n",
    "    'Simple Neural Network': simple_nn_factory,\n",
    "    'Complex Neural Network': complex_nn_factory\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_optimizer_losses(model_name, optimizer_losses, save=False):\n",
    "    \"\"\"\n",
    "    Plot the training and validation loss curves for different optimizers side by side.\n",
    "\n",
    "    Parameters:\n",
    "    model_name (str): Name of the model\n",
    "    optimizer_losses (dict): A dictionary where keys are optimizer names and values are tuples of (train_losses, val_losses)\n",
    "    save (bool): Whether to save the plot\n",
    "    \"\"\"\n",
    "    num_optimizers = len(optimizer_losses)\n",
    "    fig, axes = plt.subplots(1, num_optimizers, figsize=(num_optimizers * 6, 5), sharey=True)\n",
    "\n",
    "    for idx, (opti, (train_losses, val_losses)) in enumerate(optimizer_losses.items()):\n",
    "        avg_train_losses = np.mean(train_losses, axis=0)\n",
    "        avg_val_losses = np.mean(val_losses, axis=0)\n",
    "\n",
    "        ax = axes[idx]\n",
    "        ax.plot(avg_train_losses, label='Average Training Loss')\n",
    "        ax.plot(avg_val_losses, label='Average Validation Loss')\n",
    "        ax.set_title(f'{opti} Optimizer')\n",
    "        ax.set_xlabel('Epochs')\n",
    "        if idx == 0:\n",
    "            ax.set_ylabel('Loss')\n",
    "        ax.legend()\n",
    "\n",
    "    plt.suptitle(f'Training and Validation Loss Curves for {model_name.lower().replace(\" \", \"_\")}')\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'../assets/img/loss_curves_{model_name}.png')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running grid search for Logistic Regression with Adam\n",
      "Fold 1, Accuracy: 75.65011820330969%\n",
      "Fold 2, Accuracy: 80.33175355450237%\n",
      "Fold 3, Accuracy: 76.77725118483413%\n",
      "Fold 4, Accuracy: 74.17061611374407%\n",
      "Fold 5, Accuracy: 78.43601895734596%\n",
      "Params: {'lr': 0.001, 'betas': (0.9, 0.999)}, Accuracy: 77.07%\n",
      "Fold 1, Accuracy: 75.177304964539%\n",
      "Fold 2, Accuracy: 80.56872037914692%\n",
      "Fold 3, Accuracy: 77.01421800947867%\n",
      "Fold 4, Accuracy: 74.40758293838863%\n",
      "Fold 5, Accuracy: 78.90995260663507%\n",
      "Params: {'lr': 0.001, 'betas': (0.95, 0.999)}, Accuracy: 77.22%\n",
      "Fold 1, Accuracy: 77.06855791962175%\n",
      "Fold 2, Accuracy: 80.80568720379146%\n",
      "Fold 3, Accuracy: 77.72511848341232%\n",
      "Fold 4, Accuracy: 74.88151658767772%\n",
      "Fold 5, Accuracy: 80.09478672985782%\n",
      "Params: {'lr': 0.001, 'betas': (0.85, 0.995)}, Accuracy: 78.12%\n",
      "Fold 1, Accuracy: 70.2127659574468%\n",
      "Fold 2, Accuracy: 76.06635071090048%\n",
      "Fold 3, Accuracy: 70.61611374407583%\n",
      "Fold 4, Accuracy: 70.85308056872037%\n",
      "Fold 5, Accuracy: 72.74881516587678%\n",
      "Params: {'lr': 0.0005, 'betas': (0.9, 0.999)}, Accuracy: 72.10%\n",
      "Fold 1, Accuracy: 69.97635933806147%\n",
      "Fold 2, Accuracy: 75.11848341232228%\n",
      "Fold 3, Accuracy: 69.19431279620854%\n",
      "Fold 4, Accuracy: 71.09004739336493%\n",
      "Fold 5, Accuracy: 72.51184834123222%\n",
      "Params: {'lr': 0.0005, 'betas': (0.95, 0.999)}, Accuracy: 71.58%\n",
      "Fold 1, Accuracy: 70.68557919621749%\n",
      "Fold 2, Accuracy: 76.30331753554502%\n",
      "Fold 3, Accuracy: 71.80094786729858%\n",
      "Fold 4, Accuracy: 71.80094786729858%\n",
      "Fold 5, Accuracy: 74.40758293838863%\n",
      "Params: {'lr': 0.0005, 'betas': (0.85, 0.995)}, Accuracy: 73.00%\n",
      "Fold 1, Accuracy: 60.99290780141844%\n",
      "Fold 2, Accuracy: 61.611374407582936%\n",
      "Fold 3, Accuracy: 56.872037914691944%\n",
      "Fold 4, Accuracy: 57.58293838862559%\n",
      "Fold 5, Accuracy: 61.611374407582936%\n",
      "Params: {'lr': 0.0001, 'betas': (0.9, 0.999)}, Accuracy: 59.73%\n",
      "Fold 1, Accuracy: 61.22931442080378%\n",
      "Fold 2, Accuracy: 62.322274881516584%\n",
      "Fold 3, Accuracy: 56.161137440758296%\n",
      "Fold 4, Accuracy: 57.58293838862559%\n",
      "Fold 5, Accuracy: 61.13744075829384%\n",
      "Params: {'lr': 0.0001, 'betas': (0.95, 0.999)}, Accuracy: 59.69%\n",
      "Fold 1, Accuracy: 59.33806146572104%\n",
      "Fold 2, Accuracy: 62.322274881516584%\n",
      "Fold 3, Accuracy: 57.81990521327014%\n",
      "Fold 4, Accuracy: 58.056872037914694%\n",
      "Fold 5, Accuracy: 62.796208530805686%\n",
      "Params: {'lr': 0.0001, 'betas': (0.85, 0.995)}, Accuracy: 60.07%\n",
      "Fold 1, Accuracy: 51.30023640661938%\n",
      "Fold 2, Accuracy: 57.345971563981045%\n",
      "Fold 3, Accuracy: 51.4218009478673%\n",
      "Fold 4, Accuracy: 50.23696682464455%\n",
      "Fold 5, Accuracy: 55.92417061611374%\n",
      "Params: {'lr': 5e-05, 'betas': (0.9, 0.999)}, Accuracy: 53.25%\n",
      "Fold 1, Accuracy: 53.664302600472816%\n",
      "Fold 2, Accuracy: 53.791469194312796%\n",
      "Fold 3, Accuracy: 50.71090047393365%\n",
      "Fold 4, Accuracy: 48.81516587677725%\n",
      "Fold 5, Accuracy: 56.161137440758296%\n",
      "Params: {'lr': 5e-05, 'betas': (0.95, 0.999)}, Accuracy: 52.63%\n",
      "Fold 1, Accuracy: 58.392434988179666%\n",
      "Fold 2, Accuracy: 57.10900473933649%\n",
      "Fold 3, Accuracy: 49.28909952606635%\n",
      "Fold 4, Accuracy: 51.8957345971564%\n",
      "Fold 5, Accuracy: 54.02843601895734%\n",
      "Params: {'lr': 5e-05, 'betas': (0.85, 0.995)}, Accuracy: 54.14%\n",
      "Best parameters for Logistic Regression using Adam: {'lr': 0.001, 'betas': (0.85, 0.995)}, Best Accuracy: 78.11513338487221%\n",
      "\n",
      "Training Logistic Regression with Adam using best parameters\n",
      "Fold 1, Accuracy: 75.177304964539%\n",
      "Fold 2, Accuracy: 78.01418439716312%\n",
      "Fold 3, Accuracy: 78.72340425531915%\n",
      "Fold 4, Accuracy: 80.85106382978724%\n",
      "Fold 5, Accuracy: 80.85106382978724%\n",
      "Fold 6, Accuracy: 87.23404255319149%\n",
      "Fold 7, Accuracy: 80.85106382978724%\n",
      "Fold 8, Accuracy: 81.56028368794327%\n",
      "Fold 9, Accuracy: 75.177304964539%\n",
      "Fold 10, Accuracy: 70.92198581560284%\n",
      "Fold 11, Accuracy: 81.56028368794327%\n",
      "Fold 12, Accuracy: 78.57142857142857%\n",
      "Fold 13, Accuracy: 82.14285714285714%\n",
      "Fold 14, Accuracy: 82.85714285714286%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 1/4 [02:59<08:57, 179.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 15, Accuracy: 79.28571428571429%\n",
      "Average Cross-Validation Accuracy: 79.59%\n",
      "\n",
      "Running grid search for Logistic Regression with SGD_Nesterov\n",
      "Fold 1, Accuracy: 87.70685579196217%\n",
      "Fold 2, Accuracy: 90.04739336492891%\n",
      "Fold 3, Accuracy: 88.86255924170617%\n",
      "Fold 4, Accuracy: 87.44075829383887%\n",
      "Fold 5, Accuracy: 90.99526066350711%\n",
      "Params: {'lr': 0.01, 'momentum': 0.95, 'nesterov': True}, Accuracy: 89.01%\n",
      "Fold 1, Accuracy: 84.86997635933807%\n",
      "Fold 2, Accuracy: 88.86255924170617%\n",
      "Fold 3, Accuracy: 85.07109004739337%\n",
      "Fold 4, Accuracy: 84.12322274881517%\n",
      "Fold 5, Accuracy: 89.0995260663507%\n",
      "Params: {'lr': 0.01, 'momentum': 0.9, 'nesterov': True}, Accuracy: 86.41%\n",
      "Fold 1, Accuracy: 82.50591016548464%\n",
      "Fold 2, Accuracy: 86.49289099526067%\n",
      "Fold 3, Accuracy: 81.75355450236967%\n",
      "Fold 4, Accuracy: 79.38388625592417%\n",
      "Fold 5, Accuracy: 85.54502369668246%\n",
      "Params: {'lr': 0.01, 'momentum': 0.8, 'nesterov': True}, Accuracy: 83.14%\n",
      "Fold 1, Accuracy: 85.81560283687944%\n",
      "Fold 2, Accuracy: 88.15165876777252%\n",
      "Fold 3, Accuracy: 85.07109004739337%\n",
      "Fold 4, Accuracy: 84.36018957345972%\n",
      "Fold 5, Accuracy: 88.62559241706161%\n",
      "Params: {'lr': 0.005, 'momentum': 0.95, 'nesterov': True}, Accuracy: 86.40%\n",
      "Fold 1, Accuracy: 81.7966903073286%\n",
      "Fold 2, Accuracy: 86.01895734597156%\n",
      "Fold 3, Accuracy: 82.22748815165876%\n",
      "Fold 4, Accuracy: 79.62085308056872%\n",
      "Fold 5, Accuracy: 85.54502369668246%\n",
      "Params: {'lr': 0.005, 'momentum': 0.9, 'nesterov': True}, Accuracy: 83.04%\n",
      "Fold 1, Accuracy: 77.54137115839244%\n",
      "Fold 2, Accuracy: 81.51658767772511%\n",
      "Fold 3, Accuracy: 77.48815165876778%\n",
      "Fold 4, Accuracy: 76.77725118483413%\n",
      "Fold 5, Accuracy: 82.22748815165876%\n",
      "Params: {'lr': 0.005, 'momentum': 0.8, 'nesterov': True}, Accuracy: 79.11%\n",
      "Fold 1, Accuracy: 77.06855791962175%\n",
      "Fold 2, Accuracy: 80.33175355450237%\n",
      "Fold 3, Accuracy: 77.72511848341232%\n",
      "Fold 4, Accuracy: 75.59241706161137%\n",
      "Fold 5, Accuracy: 81.75355450236967%\n",
      "Params: {'lr': 0.001, 'momentum': 0.95, 'nesterov': True}, Accuracy: 78.49%\n",
      "Fold 1, Accuracy: 72.57683215130024%\n",
      "Fold 2, Accuracy: 76.77725118483413%\n",
      "Fold 3, Accuracy: 73.45971563981043%\n",
      "Fold 4, Accuracy: 72.51184834123222%\n",
      "Fold 5, Accuracy: 76.30331753554502%\n",
      "Params: {'lr': 0.001, 'momentum': 0.9, 'nesterov': True}, Accuracy: 74.33%\n",
      "Fold 1, Accuracy: 70.2127659574468%\n",
      "Fold 2, Accuracy: 70.85308056872037%\n",
      "Fold 3, Accuracy: 66.35071090047393%\n",
      "Fold 4, Accuracy: 69.43127962085308%\n",
      "Fold 5, Accuracy: 71.32701421800948%\n",
      "Params: {'lr': 0.001, 'momentum': 0.8, 'nesterov': True}, Accuracy: 69.63%\n",
      "Fold 1, Accuracy: 73.5224586288416%\n",
      "Fold 2, Accuracy: 77.01421800947867%\n",
      "Fold 3, Accuracy: 73.93364928909952%\n",
      "Fold 4, Accuracy: 71.80094786729858%\n",
      "Fold 5, Accuracy: 76.06635071090048%\n",
      "Params: {'lr': 0.0005, 'momentum': 0.95, 'nesterov': True}, Accuracy: 74.47%\n",
      "Fold 1, Accuracy: 69.50354609929079%\n",
      "Fold 2, Accuracy: 70.85308056872037%\n",
      "Fold 3, Accuracy: 66.58767772511848%\n",
      "Fold 4, Accuracy: 68.95734597156398%\n",
      "Fold 5, Accuracy: 71.32701421800948%\n",
      "Params: {'lr': 0.0005, 'momentum': 0.9, 'nesterov': True}, Accuracy: 69.45%\n",
      "Fold 1, Accuracy: 65.2482269503546%\n",
      "Fold 2, Accuracy: 66.11374407582939%\n",
      "Fold 3, Accuracy: 61.84834123222749%\n",
      "Fold 4, Accuracy: 63.74407582938389%\n",
      "Fold 5, Accuracy: 67.53554502369668%\n",
      "Params: {'lr': 0.0005, 'momentum': 0.8, 'nesterov': True}, Accuracy: 64.90%\n",
      "Best parameters for Logistic Regression using SGD_Nesterov: {'lr': 0.01, 'momentum': 0.95, 'nesterov': True}, Best Accuracy: 89.01056547118864%\n",
      "\n",
      "Training Logistic Regression with SGD_Nesterov using best parameters\n",
      "Fold 1, Accuracy: 87.23404255319149%\n",
      "Fold 2, Accuracy: 85.1063829787234%\n",
      "Fold 3, Accuracy: 93.61702127659575%\n",
      "Fold 4, Accuracy: 90.0709219858156%\n",
      "Fold 5, Accuracy: 90.78014184397163%\n",
      "Fold 6, Accuracy: 92.90780141843972%\n",
      "Fold 7, Accuracy: 85.81560283687944%\n",
      "Fold 8, Accuracy: 91.48936170212765%\n",
      "Fold 9, Accuracy: 87.23404255319149%\n",
      "Fold 10, Accuracy: 86.52482269503547%\n",
      "Fold 11, Accuracy: 87.94326241134752%\n",
      "Fold 12, Accuracy: 90.0%\n",
      "Fold 13, Accuracy: 90.0%\n",
      "Fold 14, Accuracy: 94.28571428571429%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 2/4 [05:41<05:38, 169.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 15, Accuracy: 92.14285714285714%\n",
      "Average Cross-Validation Accuracy: 89.68%\n",
      "\n",
      "Running grid search for Logistic Regression with AdaGrad\n",
      "Fold 1, Accuracy: 66.903073286052%\n",
      "Fold 2, Accuracy: 68.00947867298578%\n",
      "Fold 3, Accuracy: 61.84834123222749%\n",
      "Fold 4, Accuracy: 64.92890995260663%\n",
      "Fold 5, Accuracy: 68.00947867298578%\n",
      "Params: {'lr': 0.01}, Accuracy: 65.94%\n",
      "Fold 1, Accuracy: 62.88416075650118%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 2/4 [05:57<05:57, 178.77s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning grid search for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopt_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Perform grid search\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m best_params, best_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search_optimizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_preprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_preprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopt_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Best Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Train with best parameters\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 13\u001b[0m, in \u001b[0;36mgrid_search_optimizer\u001b[0;34m(model_factory, optimizer_factory, param_grid, X, y, k_folds, epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m model: optimizer_factory(model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptimizer_params)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Perform cross-validation\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m avg_accuracy, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mperform_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m avg_accuracy \u001b[38;5;241m>\u001b[39m best_accuracy:\n\u001b[1;32m     16\u001b[0m     best_accuracy \u001b[38;5;241m=\u001b[39m avg_accuracy\n",
      "Cell \u001b[0;32mIn[19], line 45\u001b[0m, in \u001b[0;36mperform_cross_validation\u001b[0;34m(model_factory, optimizer_factory, X, y, k_folds, epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     43\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optimizer_factory(model)\n\u001b[0;32m---> 45\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_validate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m all_train_losses\u001b[38;5;241m.\u001b[39mappend(train_losses)\n\u001b[1;32m     47\u001b[0m all_val_losses\u001b[38;5;241m.\u001b[39mappend(val_losses)\n",
      "Cell \u001b[0;32mIn[18], line 21\u001b[0m, in \u001b[0;36mtrain_validate_model\u001b[0;34m(model, criterion, optimizer, train_loader, val_loader, epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     20\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     22\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     23\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "File \u001b[0;32m~/miniconda/envs/advancedml/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda/envs/advancedml/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda/envs/advancedml/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/advancedml/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/advancedml/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/advancedml/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_preprocessed, y_preprocessed = preprocess_data(X, y)\n",
    "\n",
    "optimizers = {\n",
    "    'Adam': (adam_factory, adam_grid),\n",
    "    'SGD_Nesterov': (sgd_nesterov_factory, sgd_grid),\n",
    "    'AdaGrad': (adagrad_factory, adagrad_grid),\n",
    "    'RMSProp': (rmsprop_factory, rmsprop_grid)\n",
    "}\n",
    "\n",
    "for model_name, model_factory in models.items():\n",
    "    optimizer_losses = {}\n",
    "    for opt_name, (opt_factory, opt_grid) in tqdm(optimizers.items()):\n",
    "        print(f\"\\nRunning grid search for {model_name} with {opt_name}\")\n",
    "        \n",
    "        # Perform grid search\n",
    "        best_params, best_accuracy = grid_search_optimizer(\n",
    "            model_factory, opt_factory, opt_grid, X_preprocessed, y_preprocessed, k_folds=5, epochs=120\n",
    "        )\n",
    "        print(f\"Best parameters for {model_name} using {opt_name}: {best_params}, Best Accuracy: {best_accuracy}%\")\n",
    "\n",
    "        # Train with best parameters\n",
    "        optimized_optimizer_factory = lambda model: opt_factory(model, **best_params)\n",
    "        print(f\"\\nTraining {model_name} with {opt_name} using best parameters\")\n",
    "        avg_accuracy, all_train_losses, all_val_losses = perform_cross_validation(\n",
    "            model_factory, optimized_optimizer_factory, X_preprocessed, y_preprocessed, k_folds=15, epochs=120\n",
    "        )\n",
    "\n",
    "        #lot_train_val_losses(all_train_losses, all_val_losses, model=model_name, opti=opt_name, save=True)\n",
    "        # Collect losses for plotting\n",
    "        optimizer_losses[opt_name] = (all_train_losses, all_val_losses)\n",
    "        \n",
    "        print(f'Average Cross-Validation Accuracy: {round(avg_accuracy, 2)}%')\n",
    "        \n",
    "    # Plot losses for all optimizers of the current model\n",
    "    plot_optimizer_losses(model_name, optimizer_losses, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advancedml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
